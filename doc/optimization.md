# 시스템 최적화 및 아키텍처 가이드

본 문서는 LGD liteStat 시스템이 대규모 제조 데이터 분석을 처리하기 위해 채택한 아키텍처 결정 사항과 성능 최적화 기법을 상세히 설명합니다.

## 1. 고성능 아키텍처 (High-Performance Architecture)

### 1.1 기술 스택 선정 이유
- **Backend**: Go (Golang) 1.24+
  - 높은 동시성 처리 능력, 낮은 지연 시간(Latency), 그리고 하드웨어 자원을 직접 제어할 수 있는 능력 때문에 선정되었습니다.
  - 델타 계산 및 집계와 같은 무거운 연산 작업에 적합합니다.
- **Database**: DuckDB (Embedded OLAP)
  - 분석 쿼리(OLAP)에 최적화된 컬럼 기반(Columnar) 스토리지 엔진입니다.
  - 집계 쿼리(`SUM`, `AVG`, `GROUP BY`)에서 기존 행 기반 데이터베이스(PostgreSQL/MySQL)보다 10~100배 빠른 성능을 제공합니다.
  - **벡터화 실행(Vectorized Execution)**: 데이터를 행 단위가 아닌 배치 단위로 처리하여 CPU 캐시 효율을 극대화합니다.
- **Frontend**: Svelte + Vite
  - 매우 효율적인 바닐라 JS로 컴파일됩니다.
  - Virtual DOM 오버헤드가 없어, 대용량 데이터 테이블과 차트를 렌더링할 때 React 등에 비해 월등히 빠릅니다.

### 1.2 공장 기반 파티셔닝 (Facility-Based Partitioning)
- **전략**: 데이터는 공장 코드(예: `A1T`, `B2T`)별로 물리적으로 분리되어 저장됩니다.
- **구현**:
  - 경로: `data/{facility_code}/duck.db`
  - **엄격한 격리**: 한 공장에 대한 쿼리가 다른 공장의 I/O에 영향을 주지 않도록 보장합니다.
  - **확장성**: 새로운 공장을 추가할 때는 폴더를 생성하고 설정에 추가하기만 하면 되며, 기존 데이터에는 전혀 영향을 주지 않습니다.

---

## 2. 데이터 최적화 전략

### 2.1 "Glass Stats" 데이터 마트
원본 검사 데이터(`lake_mgr.eas_pnl_ins_def_a`)는 결함 단위로 저장되므로 매우 방대합니다. 분석 요청 때마다 이 원본 테이블을 조회하는 것은 비효율적입니다.

**해결책: Materialized Mart (`glass_stats`)**
- 서버 시작 시 미리 집계된 테이블을 생성/갱신합니다.
- **집계 수준**: `Glass ID` + `Lot ID` 수준으로 요약됩니다.
- **스키마**:
  ```sql
  CREATE TABLE glass_stats (
      glass_id TEXT PRIMARY KEY,
      lot_id TEXT,
      work_date DATE,
      total_defects INTEGER, -- 미리 계산된 합계
      defect_indices BLOB    -- 빠른 히트맵 생성을 위한 비트셋 또는 리스트
  );
  ```
- **이점**:
  - 분석 쿼리는 1,000만 건 이상의 `inspection` 테이블 대신 10만 건 수준의 `glass_stats`를 조회합니다.
  - 쿼리 시간이 약 5초에서 **50ms** 수준으로 단축됩니다.

### 2.2 가중 평균(Weighted Average) 계산
장비 성능을 정확하게 비교하기 위해 특정 가중 평균 로직을 사용하며, 속도를 위해 SQL 내부에서 처리합니다.

- **델타 로직**: `장비 불량률 - 전체 그룹 평균`
- **최적화**: 이 복잡한 계산은 윈도우 함수(`OVER (PARTITION BY process_code)`)를 사용하여 단일 최적화 SQL 쿼리로 수행됩니다. 애플리케이션 레벨의 루프를 제거하여 속도를 높였습니다.

### 2.3 Mock 데이터 생성
- **벌크 인서트**: Mock 데이터는 메모리에서 생성된 후 DuckDB의 `Appender` 인터페이스(청크 단위 삽입)를 사용하여 삽입됩니다. 초당 100만 건 이상의 데이터를 삽입할 수 있습니다.
- **현실적인 분포**: 실제 제조 불량 패턴을 시뮬레이션하기 위해 정규 분포 곡선을 따르도록 데이터가 생성됩니다.

---

## 3. 애플리케이션 성능

### 3.1 Go 워커 풀 (Worker Pool)
- **문제**: 동시에 여러 개의 무거운 분석 요청이 들어오면 CPU 자원이 고갈될 수 있습니다.
- **해결책**: 버퍼링된 워커 풀 (기본 크기 4, 설정 가능)을 도입했습니다.
- **동작**:
  - 들어오는 요청은 큐에 대기합니다.
  - 워커들은 코어 수에 맞춰 작업을 순차적으로 처리합니다.
  - 과부하 상태에서도 시스템(서버)이 멈추지 않고 안정적으로 동작하게 합니다.

### 3.2 캐싱 전략
- **결과 캐시**: 분석 결과는 요청 파라미터의 MD5 해시를 키(Key)로 하여 인메모리 맵(또는 SQLite)에 캐싱됩니다.
- **적중률(Hit Rate)**: 동일한 쿼리(예: 여러 사용자가 같은 대시보드를 보는 경우)는 **0ms**의 지연 시간으로 즉시 반환됩니다.

### 3.3 스트리밍 응답 (SSE)
- **문제**: 30일치 대량 데이터를 분석할 때는 10초 이상 소요될 수 있습니다.
- **해결책**: Server-Sent Events (SSE)를 도입했습니다.
- **사용자 경험**: 사용자는 멈춘 화면 대신 실시간 진행률(0% -> 100%)을 볼 수 있어 심리적 대기 시간을 줄입니다.

---

## 4. 프론트엔드 최적화

### 4.1 Plotly.js 최적화
- **WebGL**: 산점도(Scatter Plot)는 `type: 'scattergl'`을 사용하여 WebGL 렌더링을 활성화했습니다. 5만 개 이상의 포인트도 브라우저 렉 없이 부드럽게 표현됩니다.
- **반응형 레이아웃**: `ResizeObserver`를 사용하여 차트 리사이징을 효율적으로 처리합니다.

---

## 5. 향후 최적화 로드맵
- **Parquet 스토리지**: DuckDB 네이티브 파일에서 Parquet 파일로 전환하여 압축률을 높이고 Spark/Presto 등과의 상호운용성을 확보할 예정입니다.
- **샤딩(Sharding)**: 단일 공장 데이터가 1TB를 초과할 경우, 연/월 단위로 물리적 파일을 분할(Sharding)할 계획입니다.
- **GPU 가속**: 결함 패턴 인식(히트맵 분석) 시 CUDA를 활용한 행렬 연산 가속을 검토 중입니다.
